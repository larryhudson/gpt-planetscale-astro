---
import Layout from "@src/components/Layout.astro";
import * as db from "@src/utils/db";
import MarkdownIt from "markdown-it";
import { redirectUserIfNotApproved } from "@src/utils/auth";

const idParam = Astro.params.id;
if (!idParam) return Astro.redirect("/conversations");

const id = parseInt(idParam);

const user = await redirectUserIfNotApproved(Astro);

const conversation = await db.getConversationById(id);

if (conversation.user_id !== user.id) {
  return Astro.redirect("/conversations?reason=not-allowed");
}

const md = new MarkdownIt();

if (Astro.request.method === "POST") {
  const formData = await Astro.request.formData();
  const type = formData.get("type");
  const action = formData.get("action") || "addMessage";
  if (action === "getGptMessage") {
    await db.getGptMessageForConversation(id);
  } else {
    const content = formData.get("content");
    const messageData = {
      type,
      content,
      conversation_id: id,
    } as db.Message;
    await db.createMessage(messageData);
  }
}

const messages = await db.getMessagesForConversation(id);
const systemPrompt = await db.getSystemPromptById(
  conversation.system_prompt_id
);
---

<Layout>
  <div id="page-container">
    <div id="messages-window">
      <div id="messages">
        {
          messages.map((message) => (
            <section data-message-container data-speaker={message.type}>
              <div set:html={md.render(message.content)} data-content />
              <button data-action="speak" type="button">
                🔈
              </button>
            </section>
          ))
        }
      </div>
    </div>

    <form id="new-message-form" method="POST">
      <input type="hidden" name="type" value="user" />
      <input
        type="hidden"
        id="conversation-id"
        name="conversationId"
        value={id}
      />

      <div class="buttons">
        <button type="button" data-action="record">🎤 Record</button>
        <button type="button" data-action="clear">Clear</button>
      </div>

      <label>
        Write your message:
        <textarea id="new-message" name="content"></textarea>
      </label>
      <button type="submit">Add</button>
      <button type="button" data-action="autocomplete">Autocomplete</button>
    </form>
  </div>

  <script>
    import AudioRecorder from "audio-recorder-polyfill";
    window.MediaRecorder = AudioRecorder;

    const selectButtons = document.querySelectorAll("[data-action=select]");
    selectButtons.forEach((button) => {
      button.addEventListener("click", () => {
        const contentElement =
          button.parentElement.querySelector("[data-content]");
        window.getSelection().selectAllChildren(contentElement);
      });
    });

    const recordButton = document.querySelector("[data-action=record]");
    recordButton.addEventListener("click", async () => {
      if (window.mediaRecorder && window.mediaRecorder.state === "recording") {
        stopRecording();
      } else {
        await initialiseRecorder();
        startRecording();
      }
    });

    async function initialiseRecorder() {
      // set up audio recorder and assign to global variable
      const audioStream = await navigator.mediaDevices.getUserMedia({
        audio: true,
        video: false,
      });

      let mimetype = "audio/webm";
      window.mediaFileExt = "webm";

      try {
        window.mediaRecorder = new MediaRecorder(audioStream, {
          mimeType: mimetype,
        });
      } catch (err) {
        mimetype = "video/mp4";
        window.mediaFileExt = "mp4";
        window.mediaRecorder = new MediaRecorder(audioStream, {
          mimeType: mimetype,
        });
      }

      const audioChunks = [];
      window.audioChunks = audioChunks;

      window.mediaRecorder.addEventListener("dataavailable", (event) => {
        audioChunks.push(event.data);
      });

      window.mediaRecorder.addEventListener("stop", async () => {
        const audioBlob = new Blob(audioChunks);

        // make formData
        const formData = new FormData();
        const file = new File([audioBlob], "audio", {
          type: mimetype,
        });
        formData.append("file", file);
        formData.append("fileExt", window.mediaFileExt);

        // send formData to /api/transcribe
        const response = await fetch("/api/transcribe", {
          method: "POST",
          body: formData,
        });
        const data = await response.json();
        const newMessageTextarea = document.querySelector(
          "#new-message"
        ) as HTMLTextAreaElement;

        // if there's already text in the textarea, add a new line
        if (newMessageTextarea.value) {
          newMessageTextarea.value += "\n";
        }

        newMessageTextarea.value += data.text;

        // clear the recorder
        audioChunks.length = 0;
      });
    }

    async function startRecording() {
      await initialiseRecorder();
      window.mediaRecorder.start();
      recordButton.textContent = "⏹️ Stop";
    }

    async function stopRecording() {
      window.mediaRecorder.stop();
      recordButton.textContent = "🎤 Record";
    }

    // clear button should clear the input
    const clearButton = document.querySelector("[data-action=clear]");
    clearButton.addEventListener("click", () => {
      const newMessageTextarea = document.querySelector(
        "#new-message"
      ) as HTMLTextAreaElement;
      newMessageTextarea.value = "";
    });
  </script>
  <script>
    document.addEventListener("click", (event) => {
      const target = event.target as HTMLElement;
      if (target.dataset.action === "speak") {
        const containerTag = target.closest("[data-message-container]");

        speakContent(containerTag);
      }
    });

    async function speakContent(messageContainer) {
      // if the message is already speaking, don't do anything
      if (messageContainer.dataset.speaking === "true" && window.currentAudio) {
        window.currentAudio.pause();
        window.currentAudio.currentTime = 0;
        messageContainer.dataset.speaking = "false";
        return;
      }

      // set the state to speaking
      messageContainer.dataset.speaking = "pending";

      // send content to tts API URL
      const ttsApiUrl = `/api/tts`;

      const content =
        messageContainer.querySelector("[data-content]").textContent;

      const audioResponse = await fetch(ttsApiUrl, {
        method: "POST",
        body: JSON.stringify({
          text: content,
        }),
        headers: {
          "Content-Type": "application/json",
        },
      });

      console.log(audioResponse);

      // add the audioResponse to the mediastream
      const blob = await audioResponse.blob();

      const audio = new Audio();
      audio.src = URL.createObjectURL(blob);
      audio.play();

      window.currentAudio = audio;

      // set the state to speaking
      messageContainer.dataset.speaking = "true";

      // when the audio finishes, reset the state
      audio.addEventListener("ended", () => {
        messageContainer.dataset.speaking = "false";
      });
    }

    window.speakContent = speakContent;
  </script>
  <script src="../../scripts/stream-chat.js"></script>
  <script>
    const newMessageTextarea = document.querySelector("#new-message");

    const messages = document.querySelector("#messages");

    const autocompleteButton = document.querySelector(
      "[data-action=autocomplete]"
    );

    const autocomplete = async () => {
      const text = newMessageTextarea.value;
      const conversationId = document.querySelector("#conversation-id").value;

      const formData = new FormData();

      formData.append("text", text);
      formData.append("conversationId", conversationId);
      formData.append("action", "getGptCompletion");

      const response = await fetch("/api/gpt", {
        method: "POST",
        body: formData,
      });

      const data = await response.json();

      newMessageTextarea.dataset.previousValue = newMessageTextarea.value;
      newMessageTextarea.value = data.text;

      // add a button for undoing
      const undoButton = document.createElement("button");
      undoButton.textContent = "Undo";
      undoButton.dataset.action = "undo";

      autocompleteButton.after(undoButton);

      undoButton.addEventListener("click", () => {
        newMessageTextarea.value = newMessageTextarea.dataset.previousValue;
        undoButton.remove();
      });
    };

    autocompleteButton.addEventListener("click", autocomplete);
  </script>
</Layout>

<style is:global>
  #page-container {
    display: flex;
    flex-direction: column;
    height: calc(100vh - 60px);
  }

  #messages-window {
    flex-grow: 1;
    overflow-y: scroll;
  }

  section {
    margin-bottom: 1rem;
  }

  textarea {
    display: block;
    width: 100%;
  }

  /* styles for chat interface */
  #messages {
    display: flex;
    flex-direction: column;
    height: 100%;
    overflow-y: scroll;
  }

  #messages section {
    margin-bottom: 1rem;
  }
  #new-message-form textarea {
    height: 100px;
  }

  #new-message-form button {
    margin-top: 1rem;
  }

  /* make buttons big and clickable */
  button {
    padding: 1rem;
    font-size: 1.5rem;
  }

  button:active {
    background: #eee;
  }

  button:focus {
    outline: none;
  }

  button:disabled {
    opacity: 0.5;
  }

  /* show buttons side by side, 50% each */
  .buttons {
    display: flex;
    flex-direction: row;
    justify-content: space-between;
  }

  input[type="text"],
  input[type="number"],
  textarea {
    font-size: 16px;
  }

  #messages {
    display: flex;
    flex-direction: column;
    height: 100%;
    overflow-y: scroll;
  }

  #messages section {
    padding: 1rem;
    border-radius: 0.5rem;
    width: 80%;
    max-width: 32rem;
    position: relative;
  }

  section[data-speaker="user"] {
    align-self: flex-end;
    background-color: #e6f3ff;
  }

  section[data-speaker="assistant"] {
    align-self: flex-start;
    /* grey background color */
    background-color: #f2f2f2;
  }

  #messages section[data-speaking="true"] {
    /* light yellow bg */
    background-color: #fff9c4;
  }
</style>
